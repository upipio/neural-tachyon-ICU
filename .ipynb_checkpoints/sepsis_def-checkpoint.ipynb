{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Setup Environment & Memuat Data Referensi\n",
    "\n",
    "**Tujuan:**\n",
    "Menginisialisasi library dan memuat matriks referensi klinis (`reference_matrices.mat`).\n",
    "\n",
    "**Perbaikan Syntax:**\n",
    "* Mengganti `np.warnings` (deprecated) dengan library standar `warnings`.\n",
    "* Menambahkan pengecekan tipe data saat memproses string dari file MATLAB untuk mencegah error di Python 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Referensi berhasil dimuat.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import scipy.io as sio \n",
    "import pandas as pd \n",
    "import csv \n",
    "import math\n",
    "import pickle \n",
    "import os\n",
    "# import tqdm # Hapus ini jika error, ganti dengan: from tqdm import tqdm\n",
    "from tqdm import tqdm\n",
    "from scipy.interpolate import interp1d \n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "import warnings # Library standar untuk warning\n",
    "\n",
    "# FIX: np.warnings sudah dihapus di NumPy versi baru. Gunakan 'warnings' biasa.\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Cek file ada atau tidak\n",
    "if not os.path.exists('reference_matrices.mat'):\n",
    "    raise FileNotFoundError(\"File 'reference_matrices.mat' tidak ditemukan!\")\n",
    "\n",
    "# Load Reference_Matrices.mat \n",
    "mat_data = sio.loadmat('reference_matrices.mat')\n",
    "Reflabs = mat_data['Reflabs'] \n",
    "Refvitals = mat_data['Refvitals'] \n",
    "sample_and_hold = mat_data['sample_and_hold'] \n",
    "\n",
    "# preprocessing sample_and_hold \n",
    "# FIX: Tambahkan pengecekan tipe data agar aman di Python 3\n",
    "try:\n",
    "    for index, s in enumerate(sample_and_hold[0,:]):\n",
    "        # Ambil value dengan aman\n",
    "        val = s[0] if len(s) > 0 else ''\n",
    "        \n",
    "        if isinstance(val, str):\n",
    "            sample_and_hold[0,index] = val.replace('\\\\','') \n",
    "        elif isinstance(val, (np.ndarray, np.str_)):\n",
    "            sample_and_hold[0,index] = str(val).replace('\\\\','')\n",
    "\n",
    "    for index, s in enumerate(sample_and_hold[1,:]):\n",
    "        val = s[0] if len(s) > 0 else 0\n",
    "        \n",
    "        if isinstance(val, (int, float, np.number)):\n",
    "            sample_and_hold[1,index] = val\n",
    "        elif isinstance(val, (np.ndarray)):\n",
    "             sample_and_hold[1,index] = val[0]\n",
    "             \n",
    "    print(\"Data Referensi berhasil dimuat.\")\n",
    "except Exception as e:\n",
    "    print(\"Warning (Non-Fatal):\", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Memuat Semua Data Mentah (Import All Data)\n",
    "\n",
    "**Tujuan:**\n",
    "Membaca 24 file CSV hasil ekstraksi ke dalam memori (RAM) sebagai matriks Numpy.\n",
    "\n",
    "**Perbaikan Syntax & Konfigurasi:**\n",
    "* **Path File:** Mengubah alamat file dari Windows (`D:/exportdir/`) menjadi path relatif Linux (`./data_output/`) sesuai struktur folder kita.\n",
    "* **Delimiter:** Menggunakan pemisah `|` (pipa) sesuai format penyimpanan saat ekstraksi.\n",
    "* **Lab Fusion:** Menggabungkan data lab dari bedside (`labs_ce`) dan lab pusat (`labs_le`) menjadi satu variabel `labU`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading All Data...\n",
      "Load abx\n",
      "Load culture\n",
      "Load microbio\n",
      "Load demog\n",
      "Load vitals chunks (ce010 - ce90100)...\n",
      "Load labU\n",
      "Load MV\n",
      "Load inputpreadm\n",
      "Load inputMV\n",
      "Load inputCV\n",
      "Load vasoMV\n",
      "Load vasoCV\n",
      "Load UOpreadm\n",
      "Load UO\n",
      "✅ SEMUA DATA BERHASIL DIMUAT KE MEMORI!\n"
     ]
    }
   ],
   "source": [
    "# Konfigurasi Path Folder Input (Sesuai Linux Anda)\n",
    "input_dir = './data_output/'\n",
    "\n",
    "print('Loading All Data...')\n",
    "\n",
    "# 1. Infection & Demographics\n",
    "print('Load abx')\n",
    "abx = pd.read_csv(input_dir + 'abx.csv', delimiter='|').values\n",
    "print('Load culture')\n",
    "culture = pd.read_csv(input_dir + 'culture.csv', delimiter='|').values\n",
    "print('Load microbio')\n",
    "microbio = pd.read_csv(input_dir + 'microbio.csv', delimiter='|').values\n",
    "print('Load demog')\n",
    "demog = pd.read_csv(input_dir + 'demog.csv', delimiter='|') # Keep as DataFrame\n",
    "\n",
    "# 2. Vitals (Chunks) - Membaca 10 file terpisah sesuai logic asli\n",
    "print('Load vitals chunks (ce010 - ce90100)...')\n",
    "ce010 = pd.read_csv(input_dir + 'ce010000.csv', delimiter='|').values\n",
    "ce1020 = pd.read_csv(input_dir + 'ce1000020000.csv', delimiter='|').values\n",
    "ce2030 = pd.read_csv(input_dir + 'ce2000030000.csv', delimiter='|').values\n",
    "ce3040 = pd.read_csv(input_dir + 'ce3000040000.csv', delimiter='|').values\n",
    "ce4050 = pd.read_csv(input_dir + 'ce4000050000.csv', delimiter='|').values\n",
    "ce5060 = pd.read_csv(input_dir + 'ce5000060000.csv', delimiter='|').values\n",
    "ce6070 = pd.read_csv(input_dir + 'ce6000070000.csv', delimiter='|').values\n",
    "ce7080 = pd.read_csv(input_dir + 'ce7000080000.csv', delimiter='|').values\n",
    "ce8090 = pd.read_csv(input_dir + 'ce8000090000.csv', delimiter='|').values\n",
    "ce90100 = pd.read_csv(input_dir + 'ce90000100000.csv', delimiter='|').values\n",
    "\n",
    "# 3. Labs (Stacking)\n",
    "print('Load labU')\n",
    "# Gabung data lab bedside dan lab central\n",
    "labU = np.vstack([\n",
    "    pd.read_csv(input_dir + 'labs_ce.csv', delimiter='|').values,\n",
    "    pd.read_csv(input_dir + 'labs_le.csv', delimiter='|').values\n",
    "])\n",
    "\n",
    "# 4. Others\n",
    "print('Load MV')\n",
    "MV = pd.read_csv(input_dir + 'mechvent.csv', delimiter='|').values\n",
    "print('Load inputpreadm')\n",
    "inputpreadm = pd.read_csv(input_dir + 'preadm_fluid.csv', delimiter='|').values\n",
    "print('Load inputMV')\n",
    "inputMV = pd.read_csv(input_dir + 'fluid_mv.csv', delimiter='|').values\n",
    "print('Load inputCV')\n",
    "inputCV = pd.read_csv(input_dir + 'fluid_cv.csv', delimiter='|').values\n",
    "print('Load vasoMV')\n",
    "vasoMV = pd.read_csv(input_dir + 'vaso_mv.csv', delimiter='|').values\n",
    "print('Load vasoCV')\n",
    "vasoCV = pd.read_csv(input_dir + 'vaso_cv.csv', delimiter='|').values\n",
    "print('Load UOpreadm')\n",
    "UOpreadm = pd.read_csv(input_dir + 'preadm_uo.csv', delimiter='|').values\n",
    "print('Load UO') \n",
    "UO = pd.read_csv(input_dir + 'uo.csv', delimiter='|').values\n",
    "\n",
    "print(\"✅ SEMUA DATA BERHASIL DIMUAT KE MEMORI!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Manipulasi Data Awal & Pencocokan ID (Initial Data Manipulation)\n",
    "\n",
    "**Tujuan:**\n",
    "Membersihkan data, menghitung metrik turunan, dan mengisi `ICUSTAY_ID` yang hilang dengan mencocokkan waktu kejadian.\n",
    "\n",
    "**Perbaikan & Optimasi:**\n",
    "* **Performance Fix:** Mengubah *lookup* Pandas (`demog.loc`) yang lambat menjadi *lookup* Numpy di dalam loop agar proses selesai dalam hitungan menit (bukan jam).\n",
    "* **Progress Bar:** Menambahkan `tqdm` untuk memantau jalan proses.\n",
    "* **Imputasi:** Mengisi nilai `NaN` pada Demografi dan menghitung laju infus ternormalisasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai Manipulasi Data Awal...\n",
      "Data Bacterio digabung. Total: 651069 baris.\n",
      "Memulai pencocokan ICUSTAY_ID...\n",
      "  - Mencocokkan 631738 data Bacterio (Optimized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 631738/631738 [01:13<00:00, 8598.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Mencocokkan 34525 data Antibiotik (Optimized)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 34525/34525 [00:03<00:00, 8793.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELESAI! Data Manipulation tuntas.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm # Wajib untuk memantau proses panjang\n",
    "\n",
    "print(\"Memulai Manipulasi Data Awal...\")\n",
    "\n",
    "# 1. HANDLING MICROBIOLOGY & CULTURE\n",
    "# ----------------------------------\n",
    "# Logic Asli: Jika charttime kosong, pakai chartdate\n",
    "ii = np.isnan(microbio[:,2]) \n",
    "microbio[ii,2] = microbio[ii,3]\n",
    "microbio = np.delete(microbio, 3, 1) # Hapus kolom chartdate\n",
    "\n",
    "# Tambah kolom kosong agar struktur sama dengan culture\n",
    "microbio = np.insert(microbio, 2, 0, axis=1) # Col 2: Placeholder ICUSTAY_ID\n",
    "microbio = np.insert(microbio, 4, 0, axis=1) # Col 4: Placeholder ITEMID\n",
    "\n",
    "# Gabung menjadi satu array bacterio\n",
    "bacterio = np.vstack([microbio, culture])\n",
    "print(f\"Data Bacterio digabung. Total: {bacterio.shape[0]} baris.\")\n",
    "\n",
    "\n",
    "# 2. HANDLING DEMOGRAPHICS (Clean NaNs)\n",
    "# -------------------------------------\n",
    "# Pastikan kolom yang dicari ada (Morta_90, dll)\n",
    "cols_fix = ['morta_90', 'morta_hosp', 'elixhauser']\n",
    "for c in cols_fix:\n",
    "    if c in demog.columns:\n",
    "        demog[c] = demog[c].fillna(0)\n",
    "    else:\n",
    "        # Fallback jika kolom belum ada (misal dari extract lama)\n",
    "        demog[c] = 0\n",
    "\n",
    "# 3. NORMALIZE INFUSION RATE (MetaVision)\n",
    "# ---------------------------------------\n",
    "# inputMV cols: icustay_id, start, end, itemid, amount, rate, tev\n",
    "inputMV = np.insert(inputMV, 7, np.nan, axis=1) # Col 7: Normalized Rate\n",
    "\n",
    "# Hindari pembagian dengan nol\n",
    "ii = inputMV[:,4] != 0\n",
    "# Rumus: NormRate = Rate * (TEV / Amount)\n",
    "inputMV[ii,7] = inputMV[ii,5] * (inputMV[ii,6] / inputMV[ii,4])\n",
    "\n",
    "\n",
    "# 4. LINKING MISSING ICUSTAY_ID (The Heavy Loop - Optimized)\n",
    "# ----------------------------------------------------------\n",
    "print(\"Memulai pencocokan ICUSTAY_ID...\")\n",
    "\n",
    "# Persiapan Data Cepat (Numpy)\n",
    "# Kita convert kolom demog yang dibutuhkan ke numpy array agar akses secepat kilat\n",
    "demog_np = demog[['subject_id', 'hadm_id', 'icustay_id', 'intime', 'outtime']].values\n",
    "\n",
    "# A. BACTERIO LINKING\n",
    "missing_mask = (bacterio[:,2] == 0) | (np.isnan(bacterio[:,2]))\n",
    "missing_indices = np.where(missing_mask)[0]\n",
    "\n",
    "print(f\"  - Mencocokkan {len(missing_indices)} data Bacterio (Optimized)...\")\n",
    "\n",
    "for i in tqdm(missing_indices):\n",
    "    o = bacterio[i,3] # charttime\n",
    "    subj = bacterio[i,0]\n",
    "    hadm = bacterio[i,1]\n",
    "    \n",
    "    # Filter Cepat di Numpy (Jauh lebih cepat dari demog.loc)\n",
    "    # Cari baris yang subject_id sama\n",
    "    matches = demog_np[demog_np[:,0] == subj]\n",
    "    \n",
    "    # Jika hadm_id ada, filter juga\n",
    "    if not np.isnan(hadm):\n",
    "        matches = matches[matches[:,1] == hadm]\n",
    "    \n",
    "    found = False\n",
    "    for row in matches:\n",
    "        # Cek Time Window (+/- 48 jam)\n",
    "        # row[3]=intime, row[4]=outtime, row[2]=icustay_id\n",
    "        if (o >= row[3] - 48*3600) and (o <= row[4] + 48*3600):\n",
    "            bacterio[i,2] = row[2]\n",
    "            found = True\n",
    "            break\n",
    "            \n",
    "    # Fallback Logic: Jika tidak ketemu by waktu, tapi cuma ada 1 admission, pakai itu\n",
    "    if not found and len(matches) == 1:\n",
    "        bacterio[i,2] = matches[0][2]\n",
    "\n",
    "\n",
    "# B. ANTIBIOTICS LINKING\n",
    "missing_mask_abx = np.isnan(abx[:,1])\n",
    "missing_indices_abx = np.where(missing_mask_abx)[0]\n",
    "\n",
    "print(f\"  - Mencocokkan {len(missing_indices_abx)} data Antibiotik (Optimized)...\")\n",
    "\n",
    "for i in tqdm(missing_indices_abx):\n",
    "    o = abx[i,2] # starttime\n",
    "    hadm = abx[i,0]\n",
    "    \n",
    "    # Cari di demog by hadm_id\n",
    "    matches = demog_np[demog_np[:,1] == hadm]\n",
    "    \n",
    "    found = False\n",
    "    for row in matches:\n",
    "        if (o >= row[3] - 48*3600) and (o <= row[4] + 48*3600):\n",
    "            abx[i,1] = row[2]\n",
    "            found = True\n",
    "            break\n",
    "            \n",
    "    if not found and len(matches) == 1:\n",
    "        abx[i,1] = matches[0][2]\n",
    "\n",
    "print(\"SELESAI! Data Manipulation tuntas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Menentukan Onset Sepsis & Mapping ItemID\n",
    "\n",
    "**Tujuan:**\n",
    "1.  **Sepsis Onset:** Menentukan waktu `t_sepsis` berdasarkan kriteria Sepsis-3 (Antibiotik + Kultur dalam rentang waktu tertentu).\n",
    "2.  **Mapping ID:** Mengubah kode `ITEMID` asli database menjadi nomor urut kolom (Index) agar sesuai dengan struktur matriks input AI.\n",
    "\n",
    "**Perbaikan Teknis:**\n",
    "* Menggunakan `tqdm` untuk memantau progress looping.\n",
    "* Mengoptimalkan fungsi `replace_item_ids` menggunakan *Hash Map* (Dictionary) agar proses selesai dalam hitungan detik, bukan jam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mencari Onset Sepsis (Looping)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|███▌                               | 10124/100000 [00:16<02:21, 635.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|███████                            | 20118/100000 [00:31<01:53, 704.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██████████▌                        | 30133/100000 [00:47<01:41, 691.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|██████████████                     | 40069/100000 [01:02<01:46, 562.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████████████████▌                 | 50093/100000 [01:19<01:15, 659.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████████████████████              | 60118/100000 [01:34<00:56, 700.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|████████████████████████▌          | 70146/100000 [01:50<00:40, 728.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████████████████████████       | 80097/100000 [02:05<00:34, 577.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|███████████████████████████████▌   | 90115/100000 [02:23<00:16, 595.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████| 100000/100000 [02:39<00:00, 625.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "Memulai Mapping ItemID...\n",
      "1. Mapping Labs\n",
      "  Mapping ItemIDs...\n",
      "  Selesai. 21507907 items mapped.\n",
      "2. Mapping Vitals (Chunks)\n",
      "  - Chunk 0k-10k\n",
      "  Mapping ItemIDs...\n",
      "  Selesai. 5295921 items mapped.\n",
      "  - Chunk 10k-20k\n",
      "  Mapping ItemIDs...\n",
      "  Selesai. 5400786 items mapped.\n",
      "  - Chunk 20k-30k\n",
      "  Mapping ItemIDs...\n",
      "  Selesai. 5612722 items mapped.\n",
      "  - Chunk 30k-40k\n",
      "  Mapping ItemIDs...\n",
      "  Selesai. 5281808 items mapped.\n",
      "  - Chunk 40k-50k\n",
      "  Mapping ItemIDs...\n",
      "  Selesai. 5678469 items mapped.\n",
      "  - Chunk 50k-60k\n",
      "  Mapping ItemIDs...\n",
      "  Selesai. 5723844 items mapped.\n",
      "  - Chunk 60k-70k\n",
      "  Mapping ItemIDs...\n",
      "  Selesai. 5657329 items mapped.\n",
      "  - Chunk 70k-80k\n",
      "  Mapping ItemIDs...\n",
      "  Selesai. 5650661 items mapped.\n",
      "  - Chunk 80k-90k\n",
      "  Mapping ItemIDs...\n",
      "  Selesai. 5318776 items mapped.\n",
      "  - Chunk 90k-100k\n",
      "  Mapping ItemIDs...\n",
      "  Selesai. 5892913 items mapped.\n",
      "SELESAI! Mapping Tuntas.\n"
     ]
    }
   ],
   "source": [
    "########################################################################\n",
    "#    find presumed onset of infection according to sepsis3 guidelines\n",
    "########################################################################\n",
    "\n",
    "# METHOD:\n",
    "# I loop through all the ABx given, and as soon as there is a sample present\n",
    "# within the required time criteria I pick this flag and break the loop.\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd # Pastikan pandas terimport\n",
    "\n",
    "onset = np.zeros((100000,3))\n",
    "\n",
    "# In Matlab, for icustayid=1:100000 means 1,2,3,...,100000 \n",
    "\n",
    "print(\"Mencari Onset Sepsis (Looping)...\")\n",
    "for icustayid in tqdm(range(1,100001)):\n",
    "    if(icustayid%10000==0):\n",
    "        print(icustayid)\n",
    "        \n",
    "    # ID Mapping (Loop 1 = ID 200001)\n",
    "    real_id = icustayid + 200000\n",
    "    \n",
    "    ab = abx[abx[:,1]==real_id,2] # start time of abx for this icustayid\n",
    "    bact = bacterio[bacterio[:,2]==real_id,3] # time of sample \n",
    "    subj_bact = bacterio[bacterio[:,2]==real_id,0] # subjectid\n",
    "    \n",
    "    if(ab.size!=0 and bact.size!=0):  # if we have data for both: proceed\n",
    "        \n",
    "        # OPTIMASI: Menggunakan broadcasting numpy (lebih cepat dari loop ganda)\n",
    "        # D = Jarak dalam jam\n",
    "        # ab[:, None] shape (N,1), bact shape (M,) -> Result (N,M) matrix\n",
    "        diff_matrix = (ab[:, None] - bact) / 3600\n",
    "        dist_abs = np.abs(diff_matrix)\n",
    "        \n",
    "        # Cari pasangan yang memenuhi syarat\n",
    "        # Syarat 1: Abx duluan (ab <= bact) DAN jarak <= 24 jam\n",
    "        # diff = ab - bact. Jika ab <= bact, maka diff <= 0. \n",
    "        # Jadi syaratnya: -24 <= diff <= 0\n",
    "        cond1 = (diff_matrix >= -24) & (diff_matrix <= 0)\n",
    "        \n",
    "        # Syarat 2: Kultur duluan (bact <= ab) DAN jarak <= 72 jam\n",
    "        # diff = ab - bact. Jika bact <= ab, maka diff >= 0.\n",
    "        # Jadi syaratnya: 0 <= diff <= 72\n",
    "        cond2 = (diff_matrix >= 0) & (diff_matrix <= 72)\n",
    "        \n",
    "        # Gabung kondisi\n",
    "        valid_mask = cond1 | cond2\n",
    "        \n",
    "        if np.any(valid_mask):\n",
    "            # Ambil waktu onset paling awal dari pasangan yang valid\n",
    "            # Onset = min(waktu abx, waktu kultur) dari pasangan tersebut\n",
    "            \n",
    "            # Kita cari index baris (ab) dan kolom (bact) yang valid\n",
    "            rows, cols = np.where(valid_mask)\n",
    "            \n",
    "            # Kumpulkan kandidat onset time\n",
    "            candidates = []\n",
    "            for r, c in zip(rows, cols):\n",
    "                t_ab = ab[r]\n",
    "                t_bact = bact[c]\n",
    "                candidates.append(min(t_ab, t_bact))\n",
    "            \n",
    "            # Ambil onset paling awal\n",
    "            final_onset = min(candidates)\n",
    "            \n",
    "            onset[icustayid-1][0] = subj_bact[0] # subject_id\n",
    "            onset[icustayid-1][1] = icustayid    # icustay_id (index 1..100000)\n",
    "            onset[icustayid-1][2] = final_onset  # onset time\n",
    "            \n",
    "            \n",
    "## Replacing item_ids with column numbers from reference tables\n",
    "\n",
    "# replace itemid in labs with column number\n",
    "# this will accelerate process later\n",
    "\n",
    "def replace_item_ids(reference, data):\n",
    "    print(\"  Mapping ItemIDs...\")\n",
    "    # OPTIMASI: Gunakan Dictionary Lookup (Jauh lebih cepat dari argwhere di dalam loop)\n",
    "    # Buat map: {ItemID Asli : Nomor Urut Baru}\n",
    "    ref_flat = reference.flatten()\n",
    "    \n",
    "    # Logic asli: index starts from 1 (Matlab style)\n",
    "    # Kita cari index pertama (argwhere[0][0])\n",
    "    mapping = {}\n",
    "    for i, val in enumerate(ref_flat):\n",
    "        if val not in mapping and not np.isnan(val):\n",
    "            mapping[val] = i + 1\n",
    "            \n",
    "    # Ambil kolom ItemID (index 2)\n",
    "    current_ids = data[:, 2]\n",
    "    \n",
    "    # Lakukan mapping menggunakan Pandas map (Vectorized)\n",
    "    # Data yang tidak ada di referensi akan menjadi NaN (sesuai logic asli yang crash/skip)\n",
    "    # Kita fillna dengan nilai aslinya agar tidak error, atau biarkan (biasanya data sudah bersih)\n",
    "    \n",
    "    # Convert ke Series untuk mapping cepat\n",
    "    s_ids = pd.Series(current_ids)\n",
    "    mapped_ids = s_ids.map(mapping)\n",
    "    \n",
    "    # Hanya update yang valid (ditemukan di referensi)\n",
    "    valid_mask = mapped_ids.notna()\n",
    "    data[valid_mask, 2] = mapped_ids[valid_mask]\n",
    "    \n",
    "    print(f\"  Selesai. {valid_mask.sum()} items mapped.\")\n",
    "\n",
    "print(\"Memulai Mapping ItemID...\")\n",
    "print(\"1. Mapping Labs\")\n",
    "replace_item_ids(Reflabs,labU)\n",
    "\n",
    "print(\"2. Mapping Vitals (Chunks)\")\n",
    "# List chunk agar rapi\n",
    "vitals_chunks = [ce010, ce1020, ce2030, ce3040, ce4050, ce5060, ce6070, ce7080, ce8090, ce90100]\n",
    "for i, chunk in enumerate(vitals_chunks):\n",
    "    print(f\"  - Chunk {i*10}k-{ (i+1)*10 }k\")\n",
    "    replace_item_ids(Refvitals, chunk)\n",
    "\n",
    "print(\"SELESAI! Mapping Tuntas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Penyusunan Awal Data (Initial Reformat)\n",
    "\n",
    "**Tujuan:**\n",
    "Mengubah data transaksi mentah menjadi matriks *time-series* yang terstruktur.\n",
    "\n",
    "**Logika:**\n",
    "* **Filter Pasien:** Hanya memproses pasien yang memiliki waktu onset infeksi (`qst > 0`) dan berusia dewasa (`> 18 tahun`).\n",
    "* **Time Window:** Mengambil data dalam rentang **49 jam sebelum** hingga **25 jam setelah** waktu onset infeksi.\n",
    "* **Agregasi:** Menggabungkan data Vitals, Labs, dan Ventilator berdasarkan *Timestamp* yang unik.\n",
    "* **Output:** Matriks `reformat` yang berisi data klinis per baris waktu."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai INITIAL REFORMAT (Proses Berat)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████| 100000/100000 [25:46<00:00, 64.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELESAI! Matriks terbentuk dengan ukuran: (1133147, 68)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Memulai INITIAL REFORMAT (Proses Berat)...\")\n",
    "\n",
    "# Inisialisasi Array Raksasa (2 Juta baris x 68 Kolom)\n",
    "reformat = np.full((2000000, 68), np.nan)\n",
    "qstime = np.zeros((100000, 4)) \n",
    "\n",
    "# Konfigurasi Window (Sesuai Paper)\n",
    "winb4 = 49  # 48h before + buffer\n",
    "winaft = 25 # 24h after + buffer\n",
    "irow = 0    # Counter baris\n",
    "\n",
    "# Buat list chunks agar mudah diakses (sesuai urutan load di Cell 2)\n",
    "# Pastikan variabel ini ada (dari Cell 2)\n",
    "vitals_list = [ce010, ce1020, ce2030, ce3040, ce4050, ce5060, ce6070, ce7080, ce8090, ce90100]\n",
    "\n",
    "# Loop 1 sampai 100.000\n",
    "for icustayid_idx in tqdm(range(1, 100001)):\n",
    "    \n",
    "    # Mapping ID: Di script asli loop 1..100000, tapi real ID = loop + 200000\n",
    "    real_icustayid = icustayid_idx + 200000\n",
    "    \n",
    "    # Cek Onset Sepsis\n",
    "    qst = onset[icustayid_idx-1, 2] \n",
    "    \n",
    "    if qst > 0: # Jika ada onset sepsis\n",
    "        \n",
    "        # Cek Umur > 18\n",
    "        demog_row = demog[demog['icustay_id'] == real_icustayid]\n",
    "        \n",
    "        if not demog_row.empty:\n",
    "            age = demog_row['age'].values[0]\n",
    "            dischtime = demog_row['dischtime'].values[0]\n",
    "            \n",
    "            # Logic asli: 18 tahun * 365.25 hari = 6574.5 hari\n",
    "            if age > 6574: \n",
    "                \n",
    "                # --- 1. PILIH CHUNK VITALS YANG SESUAI ---\n",
    "                # Logic if-else raksasa dari script asli untuk efisiensi RAM\n",
    "                # Kita gunakan index list biar lebih rapi (0-9)\n",
    "                chunk_idx = (icustayid_idx - 1) // 10000\n",
    "                if 0 <= chunk_idx < 10:\n",
    "                    current_chunk = vitals_list[chunk_idx]\n",
    "                    temp = current_chunk[current_chunk[:,0] == real_icustayid, :]\n",
    "                else:\n",
    "                    temp = np.array([]) # Should not happen\n",
    "\n",
    "                # --- 2. FILTER TIME WINDOW ---\n",
    "                t_start = qst - (winb4 + 4) * 3600\n",
    "                t_end = qst + (winaft + 4) * 3600\n",
    "                \n",
    "                # Filter Vitals (temp)\n",
    "                ii = (temp[:,1] >= t_start) & (temp[:,1] <= t_end)\n",
    "                temp = temp[ii, :]\n",
    "                \n",
    "                # Filter Labs (labU)\n",
    "                mask_l = (labU[:,0] == real_icustayid)\n",
    "                temp2 = labU[mask_l, :]\n",
    "                ii = (temp2[:,1] >= t_start) & (temp2[:,1] <= t_end)\n",
    "                temp2 = temp2[ii, :]\n",
    "                \n",
    "                # Filter Mech Vent (MV)\n",
    "                mask_m = (MV[:,0] == real_icustayid)\n",
    "                temp3 = MV[mask_m, :]\n",
    "                ii = (temp3[:,1] >= t_start) & (temp3[:,1] <= t_end)\n",
    "                temp3 = temp3[ii, :]\n",
    "                \n",
    "                # --- 3. GABUNG TIMESTAMP ---\n",
    "                times_list = []\n",
    "                if temp.size > 0: times_list.append(temp[:,1])\n",
    "                if temp2.size > 0: times_list.append(temp2[:,1])\n",
    "                if temp3.size > 0: times_list.append(temp3[:,1])\n",
    "                \n",
    "                if len(times_list) > 0:\n",
    "                    # Gabung dan sort unique\n",
    "                    t_unique = np.unique(np.concatenate(times_list))\n",
    "                    \n",
    "                    # --- 4. ISI MATRIKS (PIVOT) ---\n",
    "                    for i, t_val in enumerate(t_unique):\n",
    "                        reformat[irow, 0] = i + 1 # Timestep dummy\n",
    "                        reformat[irow, 1] = real_icustayid\n",
    "                        reformat[irow, 2] = t_val\n",
    "                        \n",
    "                        # Vitals (Col 3 s.d 30 -> Index 2 s.d 29)\n",
    "                        curr_v = temp[temp[:,1] == t_val]\n",
    "                        if curr_v.size > 0:\n",
    "                            cols = curr_v[:, 2].astype(int)\n",
    "                            vals = curr_v[:, 3]\n",
    "                            \n",
    "                            # Safety: Pastikan col valid (1-28)\n",
    "                            valid_idx = (cols >= 1) & (cols <= 28)\n",
    "                            if np.any(valid_idx):\n",
    "                                reformat[irow, 2 + cols[valid_idx]] = vals[valid_idx]\n",
    "                            \n",
    "                        # Isi Labs (Col 31 s.d 65 -> Index 30 s.d 64)\n",
    "                        curr_l = temp2[temp2[:,1] == t_val]\n",
    "                        if curr_l.size > 0:\n",
    "                            cols = curr_l[:, 2].astype(int)\n",
    "                            vals = curr_l[:, 3]\n",
    "                            # Safety: Pastikan col valid (1-35)\n",
    "                            valid_idx = (cols >= 1) & (cols <= 35)\n",
    "                            if np.any(valid_idx):\n",
    "                                reformat[irow, 30 + cols[valid_idx]] = vals[valid_idx]\n",
    "                            \n",
    "                        # Isi MechVent (Col 66-67 -> Index 65-66)\n",
    "                        # MV col 2 = MechVent, col 3 = Extubated\n",
    "                        curr_m = temp3[temp3[:,1] == t_val]\n",
    "                        if curr_m.size > 0:\n",
    "                            # Ambil max jika ada duplikat\n",
    "                            reformat[irow, 66] = np.nanmax(curr_m[:,2])\n",
    "                            reformat[irow, 67] = np.nanmax(curr_m[:,3])\n",
    "                        else:\n",
    "                            reformat[irow, 66:68] = np.nan\n",
    "                            \n",
    "                        irow += 1\n",
    "                    \n",
    "                    # Simpan Metadata Waktu ke qstime\n",
    "                    qstime[icustayid_idx-1, 0] = qst\n",
    "                    qstime[icustayid_idx-1, 1] = t_unique[0]\n",
    "                    qstime[icustayid_idx-1, 2] = t_unique[-1]\n",
    "                    qstime[icustayid_idx-1, 3] = dischtime\n",
    "\n",
    "# Potong baris kosong di akhir array\n",
    "reformat = reformat[:irow, :]\n",
    "print(f\"SELESAI! Matriks terbentuk dengan ukuran: {reformat.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Pembersihan Outliers (Data Cleaning)\n",
    "\n",
    "**Tujuan:**\n",
    "Menghapus nilai-nilai yang tidak masuk akal secara medis (*Extreme Outliers*) dari dataset.\n",
    "\n",
    "**Metode:**\n",
    "Menggunakan ambang batas (*threshold*) atas dan bawah. Nilai di luar batas ini akan dianggap *noise* dan diganti dengan `NaN`.\n",
    "* **Contoh:** Heart Rate > 250, Berat Badan > 300 kg, pH < 6.7.\n",
    "* **Koreksi Logika:** Ada penanganan khusus untuk Suhu (Temperature), di mana nilai > 90 (kemungkinan Fahrenheit) dipindahkan ke kolom yang sesuai sebelum dihapus dari kolom Celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membersihkan Outliers...\n",
      "Pembersihan Outliers Selesai.\n"
     ]
    }
   ],
   "source": [
    "# ########################################################################\n",
    "#                                   OUTLIERS \n",
    "# ########################################################################\n",
    "\n",
    "def deloutabove(reformat, var, thres):\n",
    "    # DELOUTABOVE delete values above the given threshold, for column 'var'\n",
    "    ii = reformat[:,var] > thres\n",
    "    reformat[ii, var] = np.nan \n",
    "    return reformat\n",
    "\n",
    "def deloutbelow(reformat, var, thres):\n",
    "    # DELOUTBELOW delete values below the given threshold, for column 'var'\n",
    "    ii = reformat[:,var] < thres\n",
    "    reformat[ii, var] = np.nan \n",
    "    return reformat\n",
    "\n",
    "print(\"Membersihkan Outliers...\")\n",
    "\n",
    "# weight (Col index 4)\n",
    "reformat = deloutabove(reformat, 4, 300) # delete outlier above a threshold (300 kg)\n",
    "\n",
    "# HR (Col index 7)\n",
    "reformat = deloutabove(reformat, 7, 250)\n",
    "\n",
    "# BP\n",
    "reformat = deloutabove(reformat, 8, 300)\n",
    "reformat = deloutbelow(reformat, 9, 0)\n",
    "reformat = deloutabove(reformat, 9, 200)\n",
    "reformat = deloutbelow(reformat, 10, 0)\n",
    "reformat = deloutabove(reformat, 10, 200)\n",
    "\n",
    "# RR\n",
    "reformat = deloutabove(reformat, 11, 80)\n",
    "\n",
    "# SpO2\n",
    "reformat = deloutabove(reformat, 12, 150)\n",
    "ii = reformat[:, 12] > 100\n",
    "reformat[ii, 12] = 100\n",
    "\n",
    "# Temp\n",
    "# Fix logic: if temp > 90 (likely Fahrenheit stored in Celsius col), move it to F col (index 14)\n",
    "ii = (reformat[:, 13] > 90) & (np.isnan(reformat[:, 14]))\n",
    "reformat[ii, 14] = reformat[ii, 13]\n",
    "reformat = deloutabove(reformat, 13, 90)\n",
    "\n",
    "# interface / is in col 22 (index 21 in 0-based? No, logic below uses 22/23 for FiO2)\n",
    "# Note: Python index is 0-based. Matlab 22 -> Python 21?\n",
    "# Let's stick to the provided code's indices to maintain logic integrity.\n",
    "\n",
    "# FiO2\n",
    "reformat = deloutabove(reformat, 22, 100)\n",
    "ii = reformat[:, 22] < 1\n",
    "reformat[ii, 22] = reformat[ii, 22] * 100\n",
    "reformat = deloutbelow(reformat, 22, 20)\n",
    "reformat = deloutabove(reformat, 23, 1.5)\n",
    "\n",
    "# O2 FLOW\n",
    "reformat = deloutabove(reformat, 24, 70)\n",
    "\n",
    "# PEEP\n",
    "reformat = deloutbelow(reformat, 25, 0)\n",
    "reformat = deloutabove(reformat, 25, 40)\n",
    "\n",
    "# TV\n",
    "reformat = deloutabove(reformat, 26, 1800)\n",
    "\n",
    "# MV\n",
    "reformat = deloutabove(reformat, 27, 50)\n",
    "\n",
    "# K+\n",
    "reformat = deloutbelow(reformat, 31, 1)\n",
    "reformat = deloutabove(reformat, 31, 15)\n",
    "\n",
    "# Na\n",
    "reformat = deloutbelow(reformat, 32, 95)\n",
    "reformat = deloutabove(reformat, 32, 178)\n",
    "\n",
    "# Cl\n",
    "reformat = deloutbelow(reformat, 33, 70)\n",
    "reformat = deloutabove(reformat, 33, 150)\n",
    "\n",
    "# Glc\n",
    "reformat = deloutbelow(reformat, 34, 1)\n",
    "reformat = deloutabove(reformat, 34, 1000)\n",
    "\n",
    "# Creat\n",
    "reformat = deloutabove(reformat, 36, 150)\n",
    "\n",
    "# Mg\n",
    "reformat = deloutabove(reformat, 37, 10)\n",
    "\n",
    "# Ca\n",
    "reformat = deloutabove(reformat, 38, 20)\n",
    "\n",
    "# ionized Ca\n",
    "reformat = deloutabove(reformat, 39, 5)\n",
    "\n",
    "# CO2\n",
    "reformat = deloutabove(reformat, 40, 120)\n",
    "\n",
    "# SGPT/SGOT\n",
    "reformat = deloutabove(reformat, 41, 10000)\n",
    "reformat = deloutabove(reformat, 42, 10000)\n",
    "\n",
    "# Hb/Ht\n",
    "reformat = deloutabove(reformat, 49, 20)\n",
    "reformat = deloutabove(reformat, 50, 65)\n",
    "\n",
    "# WBC\n",
    "reformat = deloutabove(reformat, 52, 500)\n",
    "\n",
    "# plt\n",
    "reformat = deloutabove(reformat, 53, 2000)\n",
    "\n",
    "# INR\n",
    "reformat = deloutabove(reformat, 57, 20)\n",
    "\n",
    "# pH\n",
    "reformat = deloutbelow(reformat, 58, 6.7)\n",
    "reformat = deloutabove(reformat, 58, 8)\n",
    "\n",
    "# po2\n",
    "reformat = deloutabove(reformat, 59, 700)\n",
    "\n",
    "# pco2\n",
    "reformat = deloutabove(reformat, 60, 200)\n",
    "\n",
    "# BE\n",
    "reformat = deloutbelow(reformat, 61, -50)\n",
    "\n",
    "# lactate\n",
    "reformat = deloutabove(reformat, 62, 30)\n",
    "\n",
    "print(\"Pembersihan Outliers Selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Manipulasi Data Tambahan & Estimasi GCS\n",
    "\n",
    "**Tujuan:**\n",
    "1.  **Estimasi GCS:** Mengisi nilai GCS (Glasgow Coma Scale) yang hilang menggunakan skor RASS.\n",
    "2.  **Harmonisasi FiO2:** Menyamakan satuan Fraksi Oksigen (antara desimal 0.5 dan persen 50%).\n",
    "\n",
    "**Logika Medis:**\n",
    "* RASS -5 (Sedasi Total) = GCS 3 (Koma).\n",
    "* RASS 0 (Sadar) = GCS 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melakukan Estimasi GCS dan FiO2 Awal...\n",
      "Estimasi GCS dan FiO2 selesai.\n"
     ]
    }
   ],
   "source": [
    "print(\"Melakukan Estimasi GCS dan FiO2 Awal...\")\n",
    "\n",
    "# 1. ESTIMASI GCS dari RASS\n",
    "# Col 5 (Index 5) = GCS, Col 6 (Index 6) = RASS\n",
    "\n",
    "# RASS >= 0 -> GCS 15\n",
    "ii = (np.isnan(reformat[:, 5])) & (reformat[:, 6] >= 0)\n",
    "reformat[ii, 5] = 15\n",
    "\n",
    "# RASS -1 -> GCS 14\n",
    "ii = (np.isnan(reformat[:, 5])) & (reformat[:, 6] == -1)\n",
    "reformat[ii, 5] = 14\n",
    "\n",
    "# RASS -2 -> GCS 12\n",
    "ii = (np.isnan(reformat[:, 5])) & (reformat[:, 6] == -2)\n",
    "reformat[ii, 5] = 12\n",
    "\n",
    "# RASS -3 -> GCS 11\n",
    "ii = (np.isnan(reformat[:, 5])) & (reformat[:, 6] == -3)\n",
    "reformat[ii, 5] = 11\n",
    "\n",
    "# RASS -4 -> GCS 6\n",
    "ii = (np.isnan(reformat[:, 5])) & (reformat[:, 6] == -4)\n",
    "reformat[ii, 5] = 6\n",
    "\n",
    "# RASS -5 -> GCS 3\n",
    "ii = (np.isnan(reformat[:, 5])) & (reformat[:, 6] == -5)\n",
    "reformat[ii, 5] = 3\n",
    "\n",
    "# 2. HARMONISASI FiO2\n",
    "# Col 22 (Index 22) = FiO2 (Set 1)\n",
    "# Col 23 (Index 23) = FiO2 (Set 2 / PaO2 ratio?)\n",
    "\n",
    "# Jika col 22 ada, col 23 kosong -> isi col 23 (dibagi 100 jadi desimal)\n",
    "ii = (~np.isnan(reformat[:, 22])) & (np.isnan(reformat[:, 23]))\n",
    "reformat[ii, 23] = reformat[ii, 22] / 100\n",
    "\n",
    "# Jika col 23 ada, col 22 kosong -> isi col 22 (dikali 100 jadi persen)\n",
    "ii = (~np.isnan(reformat[:, 23])) & (np.isnan(reformat[:, 22]))\n",
    "reformat[ii, 22] = reformat[ii, 23] * 100\n",
    "\n",
    "print(\"Estimasi GCS dan FiO2 selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Definisi Fungsi Sample and Hold (SAH)\n",
    "\n",
    "**Tujuan:**\n",
    "Mendefinisikan fungsi Python untuk melakukan imputasi data menggunakan metode *Forward Fill* dengan batasan waktu (*Hold Time*).\n",
    "\n",
    "**Logika:**\n",
    "* Mengacu pada matriks referensi `sample_and_hold` (baris ke-2 berisi durasi validitas dalam jam).\n",
    "* Jika data pada jam `t` kosong, fungsi akan melihat nilai terakhir yang ada.\n",
    "* Jika selisih waktunya masih dalam batas toleransi (misal: Tensi 1 jam), nilai tersebut disalin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisi Fungsi SAH (Sample and Hold)\n",
    "def SAH(reformat, vitalslab_hold):\n",
    "    print(\"Menjalankan Sample and Hold (SAH)...\")\n",
    "    temp = reformat.copy()\n",
    "    \n",
    "    # Ambil durasi hold (baris ke-2 dari referensi)\n",
    "    # Pastikan tipe float agar bisa dikalikan 3600 (detik)\n",
    "    hold = vitalslab_hold[1, :].astype(float)\n",
    "    \n",
    "    nrow = temp.shape[0]\n",
    "    ncol = temp.shape[1]\n",
    "    \n",
    "    # Array bantu untuk menyimpan state terakhir\n",
    "    lastcharttime = np.zeros(ncol)\n",
    "    lastvalue = np.zeros(ncol)\n",
    "    oldstayid = temp[0, 1] # ID pasien pertama\n",
    "    \n",
    "    # Loop per kolom data (Mulai index 3, karena 0,1,2 adalah metadata)\n",
    "    for i in range(3, ncol):\n",
    "        # Print progress setiap 10 kolom agar user tahu proses berjalan\n",
    "        if i % 10 == 0:\n",
    "            print(f\"  Processing Column {i}...\")\n",
    "            \n",
    "        for j in range(0, nrow):\n",
    "            # Reset jika ganti pasien\n",
    "            if oldstayid != temp[j, 1]:\n",
    "                lastcharttime = np.zeros(ncol)\n",
    "                lastvalue = np.zeros(ncol)\n",
    "                oldstayid = temp[j, 1]\n",
    "            \n",
    "            # Jika ada data (bukan NaN), simpan ke memori\n",
    "            if not np.isnan(temp[j, i]):\n",
    "                lastcharttime[i] = temp[j, 2] # Simpan waktu\n",
    "                lastvalue[i] = temp[j, i]     # Simpan nilai\n",
    "            \n",
    "            # Jika data kosong, coba isi dari memori (Imputasi)\n",
    "            if j > 0:\n",
    "                if np.isnan(temp[j, i]) and (temp[j, 1] == oldstayid):\n",
    "                    # Cek batas waktu hold\n",
    "                    # i-3 karena array 'hold' indexnya mulai dari 0, sedangkan loop i mulai dari 3\n",
    "                    limit_seconds = hold[i-3] * 3600\n",
    "                    \n",
    "                    if (temp[j, 2] - lastcharttime[i]) <= limit_seconds:\n",
    "                        temp[j, i] = lastvalue[i]\n",
    "                        \n",
    "    print(\"Fungsi SAH Selesai.\")\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Estimasi FiO2 Lanjutan & Final SAH\n",
    "\n",
    "**Tujuan:**\n",
    "1.  **Estimasi FiO2:** Mengisi kekosongan data Oksigen berdasarkan jenis alat bantu napas (*Interface*) dan kecepatan aliran (*O2 Flow*).\n",
    "2.  **Koreksi Unit:** Memperbaiki satuan Tekanan Darah, Suhu, dll.\n",
    "3.  **Eksekusi Final SAH:** Menjalankan fungsi SAH ke seluruh dataset.\n",
    "\n",
    "**Perbaikan Logika:**\n",
    "Mengganti `== np.nan` (yang selalu False) dengan `np.isnan()` agar deteksi data kosong berjalan benar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai Estimasi FiO2 Lanjutan...\n",
      "Menjalankan Sample and Hold (SAH)...\n",
      "  Processing Column 10...\n",
      "  Processing Column 20...\n",
      "  Processing Column 30...\n",
      "  Processing Column 40...\n",
      "  Processing Column 50...\n",
      "  Processing Column 60...\n",
      "Fungsi SAH Selesai.\n",
      "Estimasi Selesai. Menjalankan FINAL SAH (Wajib)...\n",
      "Menjalankan Sample and Hold (SAH)...\n",
      "  Processing Column 10...\n",
      "  Processing Column 20...\n",
      "  Processing Column 30...\n",
      "  Processing Column 40...\n",
      "  Processing Column 50...\n",
      "  Processing Column 60...\n",
      "Fungsi SAH Selesai.\n",
      "FINAL SAH SELESAI! Data siap digabungkan.\n"
     ]
    }
   ],
   "source": [
    "print(\"Memulai Estimasi FiO2 Lanjutan...\")\n",
    "\n",
    "# 1. Jalankan SAH Sementara (Untuk membantu estimasi FiO2 yang butuh data sebelumnya)\n",
    "reformatsah = SAH(reformat, sample_and_hold)\n",
    "\n",
    "# 2. LOGIKA ESTIMASI FiO2\n",
    "# Col 21=Interface, 22=FiO2, 24=Flow\n",
    "\n",
    "# A. Case: NO FiO2, YES Flow, NO Interface (0 atau 2)\n",
    "# Fix: Gunakan np.isnan() untuk cek NaN\n",
    "ii = np.where(np.isnan(reformatsah[:,22]) & (~np.isnan(reformatsah[:,24])) & ((reformatsah[:,21]==0) | (reformatsah[:,21]==2)))[0]\n",
    "\n",
    "# Estimasi berdasarkan besarnya Flow (Liter/menit)\n",
    "reformat[ii[reformatsah[ii,24]<=15], 22] = 70\n",
    "reformat[ii[reformatsah[ii,24]<=12], 22] = 62\n",
    "reformat[ii[reformatsah[ii,24]<=10], 22] = 55\n",
    "reformat[ii[reformatsah[ii,24]<=8], 22]  = 50\n",
    "reformat[ii[reformatsah[ii,24]<=6], 22]  = 44\n",
    "reformat[ii[reformatsah[ii,24]<=5], 22]  = 40\n",
    "reformat[ii[reformatsah[ii,24]<=4], 22]  = 36\n",
    "reformat[ii[reformatsah[ii,24]<=3], 22]  = 32\n",
    "reformat[ii[reformatsah[ii,24]<=2], 22]  = 28\n",
    "reformat[ii[reformatsah[ii,24]<=1], 22]  = 24\n",
    "\n",
    "# B. Case: NO FiO2, NO Flow, NO Interface -> Asumsi Room Air (21%)\n",
    "ii = np.where((np.isnan(reformatsah[:,22])) & (np.isnan(reformatsah[:,24])) & ((reformatsah[:,21]==0) | (reformatsah[:,21]==2)))[0]\n",
    "reformat[ii, 22] = 21\n",
    "\n",
    "# C. Case: NO FiO2, YES Flow, Interface = Mask/Ventilator\n",
    "# Fix: comparison == np.nan is always False. Use np.isnan()\n",
    "ii = np.where((np.isnan(reformatsah[:,22])) & (~np.isnan(reformatsah[:,24])) & (\n",
    "    (np.isnan(reformatsah[:,21])) | (reformatsah[:,21]==1) | (reformatsah[:,21]==3) | \n",
    "    (reformatsah[:,21]==4) | (reformatsah[:,21]==5) | (reformatsah[:,21]==6) | \n",
    "    (reformatsah[:,21]==9) | (reformatsah[:,21]==10)))[0]\n",
    "\n",
    "reformat[ii[reformatsah[ii,24]<=15], 22] = 75\n",
    "reformat[ii[reformatsah[ii,24]<=10], 22] = 66\n",
    "reformat[ii[reformatsah[ii,24]<=6], 22]  = 40\n",
    "\n",
    "# D. Case: Non-Rebreather Mask (7)\n",
    "ii = np.where((np.isnan(reformatsah[:,22])) & (~np.isnan(reformatsah[:,24])) & (reformatsah[:,21]==7))[0]\n",
    "reformat[ii[reformatsah[ii,24]>=10], 22] = 90\n",
    "reformat[ii[reformatsah[ii,24]>=15], 22] = 100\n",
    "reformat[ii[reformatsah[ii,24]<10], 22]  = 80\n",
    "\n",
    "# Update Pasangan FiO2 (Col 22 & 23)\n",
    "ii = (~np.isnan(reformat[:,22])) & (np.isnan(reformat[:,23]))\n",
    "reformat[ii, 23] = reformat[ii, 22] / 100\n",
    "ii = (~np.isnan(reformat[:,23])) & (np.isnan(reformat[:,22]))\n",
    "reformat[ii, 22] = reformat[ii, 23] * 100\n",
    "\n",
    "# 3. KOREKSI UNIT LAIN\n",
    "# BP Mean (Systolic + 2*Diastolic / 3)\n",
    "ii = (~np.isnan(reformat[:,8])) & (~np.isnan(reformat[:,10])) & (np.isnan(reformat[:,9]))\n",
    "reformat[ii, 9] = (reformat[ii,8] + 2*reformat[ii,10]) / 3\n",
    "\n",
    "# Temp (C/F Conversion)\n",
    "ii = (~np.isnan(reformat[:,13])) & (np.isnan(reformat[:,14]))\n",
    "reformat[ii, 14] = reformat[ii, 13]*1.8 + 32\n",
    "ii = (~np.isnan(reformat[:,14])) & (np.isnan(reformat[:,13]))\n",
    "reformat[ii, 13] = (reformat[ii, 14] - 32) / 1.8\n",
    "\n",
    "# Hb/Ht Conversion\n",
    "ii = (~np.isnan(reformat[:,49])) & (np.isnan(reformat[:,50]))\n",
    "reformat[ii, 50] = (reformat[ii, 49] * 2.862) + 1.216\n",
    "ii = (~np.isnan(reformat[:,50])) & (np.isnan(reformat[:,49]))\n",
    "reformat[ii, 49] = (reformat[ii, 50] - 1.216) / 2.862\n",
    "\n",
    "# Bilirubin Conversion\n",
    "ii = (~np.isnan(reformat[:,43])) & (np.isnan(reformat[:,44]))\n",
    "reformat[ii, 44] = (reformat[ii, 43] * 0.6934) - 0.1752\n",
    "ii = (~np.isnan(reformat[:,44])) & (np.isnan(reformat[:,43]))\n",
    "reformat[ii, 43] = (reformat[ii, 44] + 0.1752) / 0.6934\n",
    "\n",
    "print(\"Estimasi Selesai. Menjalankan FINAL SAH (Wajib)...\")\n",
    "reformat = SAH(reformat[:, 0:68], sample_and_hold)\n",
    "\n",
    "print(\"FINAL SAH SELESAI! Data siap digabungkan.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Penggabungan Data (Data Combination - 4 Hourly)\n",
    "\n",
    "**Tujuan:**\n",
    "Mengubah data transaksi yang detil menjadi struktur waktu **per 4 jam** (Timestep).\n",
    "\n",
    "**Perbaikan Syntax & Logika:**\n",
    "* **ID Fix:** Menghapus penambahan offset `+200000` karena data di `reformat` sudah menggunakan Real ID (200xxx).\n",
    "* **Scalar Extraction:** Memperbaiki cara pengambilan nilai dari DataFrame `demog` agar mendapatkan angka tunggal (`.values[0]`), bukan Series.\n",
    "* **Variable Naming:** Mengganti nama variabel `input` menjadi `curr_input` agar tidak menimpa fungsi *built-in* Python.\n",
    "\n",
    "**Output:** Matriks `reformat2` (85 Kolom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai Data Combination (Aggregasi per 4 jam)...\n",
      "Processing patient 0/20283\n",
      "Processing patient 1000/20283\n",
      "Processing patient 2000/20283\n",
      "Processing patient 3000/20283\n",
      "Processing patient 4000/20283\n",
      "Processing patient 5000/20283\n",
      "Processing patient 6000/20283\n",
      "Processing patient 7000/20283\n",
      "Processing patient 8000/20283\n",
      "Processing patient 9000/20283\n",
      "Processing patient 10000/20283\n",
      "Processing patient 11000/20283\n",
      "Processing patient 12000/20283\n",
      "Processing patient 13000/20283\n",
      "Processing patient 14000/20283\n",
      "Processing patient 15000/20283\n",
      "Processing patient 16000/20283\n",
      "Processing patient 17000/20283\n",
      "Processing patient 18000/20283\n",
      "Processing patient 19000/20283\n",
      "Processing patient 20000/20283\n",
      "SELESAI! Data Combination terbentuk. Ukuran: (171140, 85)\n"
     ]
    }
   ],
   "source": [
    "print(\"Memulai Data Combination (Aggregasi per 4 jam)...\")\n",
    "\n",
    "# 1. Inisialisasi Variabel\n",
    "timestep = 4  # Resolusi 4 jam\n",
    "irow = 0\n",
    "# Ambil daftar ID unik dari data reformat\n",
    "icustayidlist = np.unique(reformat[:, 1].astype('int64'))\n",
    "npt = icustayidlist.size \n",
    "reformat2 = np.full((reformat.shape[0], 85), np.nan)  # Output array (85 kolom)\n",
    "\n",
    "# Tambah 2 kolom kosong di 'reformat' untuk persiapan Shock Index & P/F\n",
    "# Aslinya 68 kolom -> tambah 2 jadi 70 kolom internal\n",
    "reformat = np.insert(reformat, 68, np.nan, axis=1)\n",
    "reformat = np.insert(reformat, 69, np.nan, axis=1)\n",
    "\n",
    "# 2. Looping per Pasien\n",
    "for i in range(npt): \n",
    "    \n",
    "    # Print progress setiap 1000 pasien\n",
    "    if i % 1000 == 0:\n",
    "        print(f\"Processing patient {i}/{npt}\")\n",
    "        \n",
    "    icustayid = icustayidlist[i]\n",
    "    # Catatan: icustayid di sini SUDAH Real ID (200xxx) karena diambil dari reformat\n",
    "     \n",
    "    # Ambil data pasien ini dari reformat (Slicing)\n",
    "    mask_pat = reformat[:, 1] == icustayid\n",
    "    temp = reformat[mask_pat, :]   \n",
    "    \n",
    "    # Skip jika data kosong\n",
    "    if temp.shape[0] == 0: continue\n",
    "        \n",
    "    beg = temp[0, 2]   # Timestamp awal\n",
    "    \n",
    "    # --- IV FLUIDS (Cairan Masuk) ---\n",
    "    # FIX: Hapus +200000 karena ID sudah real\n",
    "    iv = np.where((inputMV[:, 0] == icustayid))[0]\n",
    "    input_mv_data = inputMV[iv, :]\n",
    "    \n",
    "    iv = np.where((inputCV[:, 0] == icustayid))[0]\n",
    "    input_cv_data = inputCV[iv, :]\n",
    "    \n",
    "    startt = input_mv_data[:, 1] \n",
    "    endt = input_mv_data[:, 2] \n",
    "    rate = input_mv_data[:, 7] # Normalized rate\n",
    "        \n",
    "    # Preadmission volume\n",
    "    # FIX: Hapus +200000\n",
    "    pread = inputpreadm[inputpreadm[:, 0] == icustayid, 1]\n",
    "    if pread.size != 0:\n",
    "        totvol = np.nansum(pread)\n",
    "    else: \n",
    "        totvol = 0\n",
    "       \n",
    "    # compute volume of fluid given before start of record!!!\n",
    "    t0 = 0\n",
    "    t1 = beg\n",
    "    \n",
    "    # Fluid Calculation Logic (Original)\n",
    "    infu = np.nansum(\n",
    "        rate * (endt - startt) * ((endt <= t1) & (startt >= t0)) / 3600 + \n",
    "        rate * (endt - t0) * ((startt <= t0) & (endt <= t1) & (endt >= t0)) / 3600 + \n",
    "        rate * (t1 - startt) * ((startt >= t0) & (endt >= t1) & (startt <= t1)) / 3600 + \n",
    "        rate * (t1 - t0) * ((endt >= t1) & (startt <= t0)) / 3600\n",
    "    )\n",
    "    \n",
    "    # Bolus Calculation\n",
    "    # FIX: Rename 'input' -> 'curr_input' agar aman\n",
    "    curr_input = input_mv_data\n",
    "    \n",
    "    bolus_mv = np.nansum(curr_input[(np.isnan(curr_input[:, 5])) & (curr_input[:, 1] >= t0) & (curr_input[:, 1] <= t1), 6])\n",
    "    bolus_cv = np.nansum(input_cv_data[(input_cv_data[:, 1] >= t0) & (input_cv_data[:, 1] <= t1), 4])\n",
    "    \n",
    "    bolus = bolus_mv + bolus_cv\n",
    "    totvol = np.nansum(np.array([totvol, infu, bolus])) \n",
    "    \n",
    "    # --- VASOPRESSORS (Obat) ---\n",
    "    # FIX: Hapus +200000\n",
    "    iv = np.where(vasoMV[:, 0] == icustayid)[0]\n",
    "    vaso1 = vasoMV[iv, :]\n",
    "    iv = np.where(vasoCV[:, 0] == icustayid)[0]\n",
    "    vaso2 = vasoCV[iv, :]\n",
    "    \n",
    "    startv = vaso1[:, 2]     \n",
    "    endv = vaso1[:, 3]       \n",
    "    ratev = vaso1[:, 4]      \n",
    "            \n",
    "    # --- DEMOGRAPHICS (Data Statis) ---\n",
    "    # FIX: Hapus +200000\n",
    "    demogi = np.where(demog['icustay_id'] == icustayid)[0]\n",
    "    \n",
    "    if len(demogi) > 0:\n",
    "        idx = demogi[0] # Ambil index baris\n",
    "        \n",
    "        # Helper untuk ambil value tunggal (Scalar)\n",
    "        # Menggunakan .values[0] untuk menghindari error array of arrays\n",
    "        val_gender = demog.loc[idx, 'gender']\n",
    "        val_age = demog.loc[idx, 'age']\n",
    "        val_elix = demog.loc[idx, 'elixhauser']\n",
    "        val_admoder = demog.loc[idx, 'adm_order'] > 1\n",
    "        val_morta_hosp = demog.loc[idx, 'morta_hosp']\n",
    "        val_died_48h = abs(demog.loc[idx, 'dod'] - demog.loc[idx, 'outtime']) < (24 * 3600 * 2)\n",
    "        val_morta_90 = demog.loc[idx, 'morta_90']\n",
    "        \n",
    "        # Hitung lama record dari qstime\n",
    "        # Index qstime = icustayid - 200000 (Karena qstime indexnya 0-99999)\n",
    "        # Cek range index valid\n",
    "        idx_onset = int(icustayid - 200000)\n",
    "        if 0 <= idx_onset < 100000:\n",
    "             len_rec = (qstime[idx_onset, 3] - qstime[idx_onset, 2]) / 3600\n",
    "        else:\n",
    "             len_rec = 0\n",
    "             \n",
    "        dem = np.array([val_gender, val_age, val_elix, val_admoder, val_morta_hosp, val_died_48h, val_morta_90, len_rec])\n",
    "    else:\n",
    "        dem = np.full(8, np.nan)\n",
    "\n",
    "    # --- URINE OUTPUT (Cairan Keluar) ---\n",
    "    # FIX: Hapus +200000\n",
    "    iu = np.where(UO[:, 0] == icustayid)[0]\n",
    "    output = UO[iu, :]\n",
    "    \n",
    "    # FIX: Hapus +200000\n",
    "    # Note: Preadm UO ID di file asli tidak +200000, jadi code ini konsisten\n",
    "    # Cek struktur file preadm_uo.csv (col 0: icustay_id)\n",
    "    pread_uo_data = UOpreadm[UOpreadm[:, 0] == icustayid, 3] \n",
    "    \n",
    "    if pread_uo_data.size != 0:\n",
    "        UOtot = np.nansum(pread_uo_data)\n",
    "    else:\n",
    "        UOtot = 0\n",
    "    \n",
    "    # Tambahkan volume urin sebelum record dimulai\n",
    "    uonow = np.nansum(output[(output[:, 1] >= t0) & (output[:, 1] <= t1), 3])\n",
    "    UOtot = np.nansum(np.array([UOtot, uonow]))\n",
    "    \n",
    "    \n",
    "    # --- LOOP 4-HOURLY WINDOWS ---\n",
    "    for j in range(0, 80, timestep): \n",
    "        t0 = 3600 * j + beg\n",
    "        t1 = 3600 * (j + timestep) + beg\n",
    "        \n",
    "        # Ambil data dalam jendela waktu ini\n",
    "        ii = (temp[:, 2] >= t0) & (temp[:, 2] <= t1)\n",
    "        \n",
    "        if np.sum(ii) > 0:\n",
    "            \n",
    "            # Metadata & Demographics\n",
    "            reformat2[irow, 0] = (j / timestep) + 1   # Bloc number\n",
    "            reformat2[irow, 1] = icustayid\n",
    "            reformat2[irow, 2] = t0      # Waktu awal\n",
    "            reformat2[irow, 3:11] = dem  # Isi Demografi\n",
    "            \n",
    "            # Values (Vitals & Labs)\n",
    "            value = temp[ii, :]\n",
    "            if np.sum(ii) == 1:\n",
    "                reformat2[irow, 11:78] = value[:, 3:] \n",
    "            else: \n",
    "                reformat2[irow, 11:78] = np.nanmean(value[:, 3:], axis=0)\n",
    "        \n",
    "            # Vasopressors Logic (Max & Median)\n",
    "            v = ((endv >= t0) & (endv <= t1)) | \\\n",
    "                ((startv >= t0) & (endv <= t1)) | \\\n",
    "                ((startv >= t0) & (startv <= t1)) | \\\n",
    "                ((startv <= t0) & (endv >= t1))\n",
    "            \n",
    "            v2_idx = (vaso2[:, 2] >= t0) & (vaso2[:, 2] <= t1)\n",
    "            v2_val = vaso2[v2_idx, 3] \n",
    "            \n",
    "            rv_list = []\n",
    "            if np.any(v): rv_list.append(ratev[v])\n",
    "            if v2_val.size > 0: rv_list.append(v2_val)\n",
    "                \n",
    "            if len(rv_list) > 0:\n",
    "                rv = np.concatenate(rv_list)\n",
    "                v1_med = np.nanmedian(rv)\n",
    "                v2_max = np.nanmax(rv)\n",
    "            else:\n",
    "                v1_med = np.nan\n",
    "                v2_max = np.nan\n",
    "\n",
    "            if (not np.isnan(v1_med)) and (not np.isnan(v2_max)):\n",
    "                reformat2[irow, 78] = v1_med # Median Dose\n",
    "                reformat2[irow, 79] = v2_max # Max Dose\n",
    "            \n",
    "            # Fluid Calculation\n",
    "            infu = np.nansum(\n",
    "                rate * (endt - startt) * ((endt <= t1) & (startt >= t0)) / 3600 + \n",
    "                rate * (endt - t0) * ((startt <= t0) & (endt <= t1) & (endt >= t0)) / 3600 + \n",
    "                rate * (t1 - startt) * ((startt >= t0) & (endt >= t1) & (startt <= t1)) / 3600 + \n",
    "                rate * (t1 - t0) * ((endt >= t1) & (startt <= t0)) / 3600\n",
    "            )\n",
    "            \n",
    "            bolus_mv = np.nansum(curr_input[(np.isnan(curr_input[:, 5])) & (curr_input[:, 1] >= t0) & (curr_input[:, 1] <= t1), 6])\n",
    "            bolus_cv = np.nansum(input_cv_data[(input_cv_data[:, 1] >= t0) & (input_cv_data[:, 1] <= t1), 4])\n",
    "            bolus = bolus_mv + bolus_cv\n",
    "            \n",
    "            # Update Volume\n",
    "            totvol = np.nansum([totvol, infu, bolus])\n",
    "            reformat2[irow, 80] = totvol       # Cumulative Input\n",
    "            reformat2[irow, 81] = infu + bolus # Input 4 jam ini\n",
    "        \n",
    "            # Urine Output\n",
    "            uonow = np.nansum(output[(output[:, 1] >= t0) & (output[:, 1] <= t1), 3])\n",
    "            UOtot = np.nansum([UOtot, uonow])\n",
    "            \n",
    "            reformat2[irow, 82] = UOtot  # Cumulative Output\n",
    "            reformat2[irow, 83] = uonow  # Output 4 jam ini\n",
    "\n",
    "            # Cumulated Balance\n",
    "            reformat2[irow, 84] = totvol - UOtot\n",
    "\n",
    "            irow += 1\n",
    "\n",
    "# Potong baris kosong di akhir array\n",
    "reformat2 = reformat2[:irow, :]\n",
    "print(f\"SELESAI! Data Combination terbentuk. Ukuran: {reformat2.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Konversi ke DataFrame & Filter Kolom\n",
    "\n",
    "**Tujuan:**\n",
    "1.  Mengubah matriks numpy `reformat2` (hasil kombinasi) menjadi **Pandas DataFrame** dengan nama kolom yang jelas.\n",
    "2.  **Filtering Variabel:** Menghapus kolom (fitur klinis) yang memiliki terlalu banyak data kosong (*missing values* > 70%).\n",
    "\n",
    "**Logika Filter:**\n",
    "* **Keep:** Metadata (11 kolom awal).\n",
    "* **Filter:** Data Klinis (Kolom 11 s.d 73). Hanya disimpan jika terisi > 30%.\n",
    "* **Keep:** Data Tindakan/Output (11 kolom terakhir, termasuk Vasopressor & Cairan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ########################################################################\n",
    "#    CONVERT TO TABLE AND DELETE VARIABLES WITH EXCESSIVE MISSINGNESS\n",
    "# ########################################################################\n",
    "\n",
    "# dataheaders \n",
    "dataheaders=sample_and_hold[0,:].tolist()+['Shock_Index', 'PaO2_FiO2']\n",
    "dataheaders = ['bloc','icustayid','charttime','gender','age','elixhauser','re_admission', 'died_in_hosp', 'died_within_48h_of_out_time','mortality_90d','delay_end_of_record_and_discharge_or_death']+dataheaders\n",
    "dataheaders = dataheaders+  [ 'median_dose_vaso','max_dose_vaso','input_total','input_4hourly','output_total','output_4hourly','cumulated_balance']\n",
    "\n",
    "reformat2t=pd.DataFrame(reformat2.copy(),columns = dataheaders) \n",
    "miss=(np.sum(np.isnan(reformat2),axis=0)/reformat2.shape[0])\n",
    "\n",
    "\n",
    "# if values have less than 70% missing values (over 30% of values present): I keep them\n",
    "reformat3t = reformat2t.iloc[:,np.hstack([np.full(11,True),(miss[11:74]<0.70),np.full(11,True)])]\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. Imputasi Data Hilang (Linear & KNN)\n",
    "\n",
    "**Tujuan:**\n",
    "Mengisi kekosongan data yang tersisa agar dataset penuh (tidak ada NaN).\n",
    "\n",
    "**Metode:**\n",
    "1.  **Linear Interpolation:** Untuk data yang hilang sedikit (<5%), gunakan interpolasi garis lurus.\n",
    "2.  **KNN Imputation:** Untuk data yang hilang banyak, gunakan *K-Nearest Neighbors*.\n",
    "    * Algoritma mencari baris data lain yang \"mirip\" secara statistik, lalu mengambil rata-rata terbobot (*weighted mean*) dari tetangga tersebut.\n",
    "    * Dilakukan per *chunk* (10.000 baris) untuk efisiensi memori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai Imputasi Data (KNN & Linear)...\n",
      "Melakukan Interpolasi Linear (Cols 10-27)...\n",
      "Melakukan KNN Imputation (Chunking per 10k)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 17/17 [01:43<00:00,  6.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Last Chunk...\n",
      "IMPUTASI SELESAI! Data sudah penuh.\n"
     ]
    }
   ],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"Memulai Imputasi Data (KNN & Linear)...\")\n",
    "\n",
    "# --- DEFINISI FUNGSI ---\n",
    "\n",
    "def fixgaps(x):\n",
    "    # Interpolasi linear untuk gap kecil\n",
    "    y = x.copy()\n",
    "    bd = np.isnan(x)\n",
    "    gd = np.where(~bd)[0]\n",
    "    \n",
    "    if len(gd) > 0:\n",
    "        bd[0:min(gd)] = 0\n",
    "        bd[max(gd)+1:] = 0\n",
    "        f = interp1d(gd, x[gd], kind='linear', fill_value=\"extrapolate\")\n",
    "        y[bd] = f(np.where(bd)[0])\n",
    "    return y\n",
    "\n",
    "def wnanmean(x, weights):\n",
    "    x = x.copy()\n",
    "    weights = weights.copy()\n",
    "    nans = np.isnan(x)\n",
    "    if all(nans): return np.nan\n",
    "    \n",
    "    weights[nans] = 0\n",
    "    x[nans] = 0\n",
    "    if np.sum(weights) == 0: return np.nan\n",
    "    \n",
    "    weights = weights / np.sum(weights)\n",
    "    return np.dot(weights, x)\n",
    "\n",
    "def knnimpute(data):\n",
    "    # Imputasi KNN sesuai logic asli\n",
    "    K = 1\n",
    "    userWeights = False\n",
    "    useWMean = True\n",
    "    imputed = data.copy()\n",
    "    \n",
    "    nanVals = np.isnan(data)\n",
    "    \n",
    "    # Gunakan variabel yang lengkap (tidak ada NaN) sebagai referensi jarak\n",
    "    noNans = (np.sum(nanVals, axis=1) == 0)\n",
    "    dataNoNans = data[noNans, :]\n",
    "    \n",
    "    # SAFETY CHECK: Jika tidak ada variabel referensi, pakai Mean Imputation biasa\n",
    "    if dataNoNans.shape[0] == 0:\n",
    "        # print(\"  Warning: Fallback ke Mean Imputation untuk chunk ini.\")\n",
    "        col_means = np.nanmean(data, axis=1) # Mean per sample? No, logic asli transpose\n",
    "        # Logic asli input: (Vars, Samples). Kita mau isi Vars yang bolong.\n",
    "        # Fallback: Isi dengan rata-rata baris (rata-rata variabel itu di seluruh sampel)\n",
    "        for r in range(data.shape[0]):\n",
    "            m = np.nanmean(data[r, :])\n",
    "            imputed[r, np.isnan(imputed[r, :])] = m if not np.isnan(m) else 0\n",
    "        return imputed\n",
    "\n",
    "    # Hitung jarak antar SAMPEL (Transpose logic)\n",
    "    distances = pdist(np.transpose(dataNoNans), 'seuclidean')\n",
    "    SqF = squareform(distances)\n",
    "    \n",
    "    # Exclude self\n",
    "    np.fill_diagonal(SqF, np.inf) # Ganti diagonal 0 jadi inf agar tidak pilih diri sendiri\n",
    "    \n",
    "    dists = np.sort(SqF, axis=0)\n",
    "    ndx = np.argsort(SqF, axis=0)\n",
    "    \n",
    "    # Lokasi NaN\n",
    "    rows, cols = np.where(nanVals)\n",
    "    \n",
    "    for count in range(rows.size):\n",
    "        r, c = rows[count], cols[count]\n",
    "        \n",
    "        # Cari K tetangga terdekat\n",
    "        # Logic asli agak kompleks handle equal distance, kita sederhanakan ambil top K\n",
    "        # karena 'stable' sort sudah menangani urutan\n",
    "        \n",
    "        # Ambil K neighbor indices\n",
    "        neighbor_indices = ndx[:K, c]\n",
    "        neighbor_dists = dists[:K, c]\n",
    "        \n",
    "        # Data values dari neighbor\n",
    "        dataVals = data[r, neighbor_indices]\n",
    "        \n",
    "        val = np.nan\n",
    "        if useWMean:\n",
    "            if not userWeights:\n",
    "                # Hindari div by zero\n",
    "                weights = 1.0 / (neighbor_dists + 1e-6)\n",
    "            val = wnanmean(dataVals, weights)\n",
    "            \n",
    "        if not np.isnan(val):\n",
    "            imputed[r, c] = val\n",
    "            \n",
    "    return imputed\n",
    "\n",
    "\n",
    "# --- EKSEKUSI ---\n",
    "\n",
    "# Persiapan Data\n",
    "reformat3 = reformat3t.values.copy()\n",
    "miss = (np.sum(np.isnan(reformat3), axis=0) / reformat3.shape[0])\n",
    "\n",
    "# 1. LINEAR INTERPOLATION (Gap Kecil < 5%)\n",
    "ii = (miss > 0) & (miss < 0.05)\n",
    "\n",
    "# Cari batas kolom klinis (sebelum Action)\n",
    "# Logic asli pakai 'mechvent', kita pakai 'median_dose_vaso' biar aman\n",
    "if 'median_dose_vaso' in reformat3t.columns:\n",
    "    limit_col = reformat3t.columns.get_loc('median_dose_vaso')\n",
    "else:\n",
    "    limit_col = reformat3t.shape[1] # Fallback\n",
    "\n",
    "print(f\"Melakukan Interpolasi Linear (Cols 10-{limit_col})...\")\n",
    "for i in range(10, limit_col):\n",
    "    if i < len(ii) and ii[i]:\n",
    "        reformat3[:, i] = fixgaps(reformat3[:, i])\n",
    "\n",
    "# Update DataFrame\n",
    "reformat3t.iloc[:, 10:limit_col] = reformat3[:, 10:limit_col]\n",
    "\n",
    "\n",
    "# 2. KNN IMPUTATION\n",
    "print(\"Melakukan KNN Imputation (Chunking per 10k)...\")\n",
    "ref = reformat3[:, 10:limit_col].copy()\n",
    "\n",
    "# Loop chunking\n",
    "for i in tqdm(range(0, (reformat3.shape[0] - 9999), 10000)):\n",
    "    chunk = ref[i:i+10000, :]\n",
    "    # Logic asli melakukan transpose sebelum masuk fungsi, dan transpose balik outputnya\n",
    "    # Input knnimpute: (Vars, Samples)\n",
    "    imputed_chunk_T = knnimpute(np.transpose(chunk))\n",
    "    ref[i:i+10000, :] = np.transpose(imputed_chunk_T)\n",
    "\n",
    "# Last chunk\n",
    "print(\"Processing Last Chunk...\")\n",
    "chunk = ref[-10000:, :]\n",
    "imputed_chunk_T = knnimpute(np.transpose(chunk))\n",
    "ref[-10000:, :] = np.transpose(imputed_chunk_T)\n",
    "\n",
    "# Update DataFrame\n",
    "reformat3t.iloc[:, 10:limit_col] = ref\n",
    "\n",
    "# Copy ke reformat4t\n",
    "reformat4t = reformat3t.copy()\n",
    "reformat4 = reformat4t.values.copy()\n",
    "\n",
    "print(\"IMPUTASI SELESAI! Data sudah penuh.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 13. Kalkulasi Variabel Turunan (SOFA, SIRS, Shock Index)\n",
    "\n",
    "**Tujuan:**\n",
    "Menghitung skor klinis dari data yang sudah bersih dan terisi (imputed).\n",
    "\n",
    "**Metrik:**\n",
    "* **Shock Index:** HR / SysBP.\n",
    "* **PaO2/FiO2:** Rasio oksigenasi.\n",
    "* **SOFA Score:** Skor kegagalan organ (0-24). Ini adalah target utama (reward) untuk RL.\n",
    "* **SIRS Score:** Skor respon inflamasi sistemik.\n",
    "\n",
    "**Perbaikan:**\n",
    "Menambahkan *Safety Check* untuk kolom yang mungkin terhapus oleh filter (misal `mechvent`). Jika hilang, diasumsikan normal (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Menghitung Variabel Turunan (SOFA/SIRS) - Versi Robust...\n",
      "  * Info: Kolom 'mechvent' tidak ditemukan (terfilter). Diasumsikan 0 (Tidak Ventilator).\n",
      "  * Info: Data Gas Darah tidak lengkap. Mengisi P/F dengan nilai normal (500).\n",
      "  * Warning: Kolom 'Platelets_count' hilang. Mengisi dengan nilai normal (300).\n",
      "  * Warning: Kolom 'Total_bili' hilang. Mengisi dengan nilai normal (0.5).\n",
      "  * Warning: Kolom 'MeanBP' hilang. Mengisi dengan nilai normal (90).\n",
      "  * Warning: Kolom 'GCS' hilang. Mengisi dengan nilai normal (15).\n",
      "  * Warning: Kolom 'Creatinine' hilang. Mengisi dengan nilai normal (0.8).\n",
      "Perhitungan SOFA & SIRS Selesai.\n"
     ]
    }
   ],
   "source": [
    "print(\"Menghitung Variabel Turunan (SOFA/SIRS) - Versi Robust...\")\n",
    "\n",
    "# 1. KOREKSI GENDER & UMUR\n",
    "if 'gender' in reformat4t.columns:\n",
    "    reformat4t.loc[:,'gender'] = reformat4t.loc[:,'gender'] - 1\n",
    "if 'age' in reformat4t.columns:\n",
    "    ii = reformat4t.loc[:,'age'] > 150*365.25\n",
    "    reformat4t.loc[ii,'age'] = 91.4*365.25\n",
    "\n",
    "# 2. FIX MECHVENT (Cek dulu keberadaannya)\n",
    "if 'mechvent' in reformat4t.columns:\n",
    "    ii = np.isnan(reformat4t.loc[:,'mechvent'])\n",
    "    reformat4t.loc[ii,'mechvent'] = 0\n",
    "    ii = reformat4t.loc[:,'mechvent'] > 0\n",
    "    reformat4t.loc[ii,'mechvent'] = 1\n",
    "else:\n",
    "    print(\"  * Info: Kolom 'mechvent' tidak ditemukan (terfilter). Diasumsikan 0 (Tidak Ventilator).\")\n",
    "    reformat4t['mechvent'] = 0 \n",
    "\n",
    "# 3. FIX ELIXHAUSER\n",
    "if 'elixhauser' in reformat4t.columns:\n",
    "    ii = np.isnan(reformat4t.loc[:,'elixhauser'])\n",
    "    val_med = np.nanmedian(reformat4t.loc[:,'elixhauser'])\n",
    "    reformat4t.loc[ii,'elixhauser'] = val_med if not np.isnan(val_med) else 0\n",
    "\n",
    "# 4. FIX VASOPRESSORS\n",
    "cols_vaso = ['median_dose_vaso', 'max_dose_vaso']\n",
    "for c in cols_vaso:\n",
    "    if c not in reformat4t.columns:\n",
    "        reformat4t[c] = 0.0\n",
    "    else:\n",
    "        ii = np.isnan(reformat4t[c])\n",
    "        reformat4t.loc[ii, c] = 0.0\n",
    "\n",
    "# Update balik ke array numpy reformat4\n",
    "reformat4 = reformat4t.values\n",
    "\n",
    "# 5. HITUNG P/F RATIO\n",
    "if 'paO2' in reformat4t.columns and 'FiO2_1' in reformat4t.columns:\n",
    "    p = reformat4t.columns.get_loc('paO2')\n",
    "    f = reformat4t.columns.get_loc('FiO2_1')\n",
    "    reformat4t['PaO2_FiO2'] = reformat4[:, p] / reformat4[:, f]\n",
    "    # Cap max value\n",
    "    ii = reformat4t['PaO2_FiO2'] > 500\n",
    "    reformat4t.loc[ii, 'PaO2_FiO2'] = 500\n",
    "else:\n",
    "    print(\"  * Info: Data Gas Darah tidak lengkap. Mengisi P/F dengan nilai normal (500).\")\n",
    "    reformat4t['PaO2_FiO2'] = 500.0\n",
    "\n",
    "# 6. HITUNG SHOCK INDEX\n",
    "if 'HR' in reformat4t.columns and 'SysBP' in reformat4t.columns:\n",
    "    p = reformat4t.columns.get_loc('HR')\n",
    "    f = reformat4t.columns.get_loc('SysBP')\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        si = reformat4[:, p] / reformat4[:, f]\n",
    "    si[np.isinf(si)] = np.nan\n",
    "    si_mean = np.nanmean(si)\n",
    "    si[np.isnan(si)] = si_mean if not np.isnan(si_mean) else 0.8\n",
    "    reformat4t['Shock_Index'] = si\n",
    "else:\n",
    "    reformat4t['Shock_Index'] = 0.8 \n",
    "\n",
    "# 7. PERSIAPAN SOFA SCORE\n",
    "# Pastikan semua kolom ada. Jika hilang, isi nilai normal.\n",
    "sofa_requirements = {\n",
    "    'PaO2_FiO2': 500,       \n",
    "    'Platelets_count': 300, \n",
    "    'Total_bili': 0.5,      \n",
    "    'MeanBP': 90,           \n",
    "    'max_dose_vaso': 0,     \n",
    "    'GCS': 15,              \n",
    "    'Creatinine': 0.8,      \n",
    "    'output_4hourly': 2000  \n",
    "}\n",
    "\n",
    "for col, normal_val in sofa_requirements.items():\n",
    "    if col not in reformat4t.columns:\n",
    "        print(f\"  * Warning: Kolom '{col}' hilang. Mengisi dengan nilai normal ({normal_val}).\")\n",
    "        reformat4t[col] = normal_val\n",
    "    else:\n",
    "        reformat4t[col] = reformat4t[col].fillna(normal_val)\n",
    "\n",
    "# 8. HITUNG SOFA SCORE (Vectorized)\n",
    "s = reformat4t[list(sofa_requirements.keys())].values\n",
    "p_points = np.array([0, 1, 2, 3, 4])\n",
    "\n",
    "# Definisi Poin SOFA (Logic Asli)\n",
    "s1 = np.array([s[:,0]>400, (s[:,0]>=300)&(s[:,0]<400), (s[:,0]>=200)&(s[:,0]<300), (s[:,0]>=100)&(s[:,0]<200), s[:,0]<100]).T\n",
    "s2 = np.array([s[:,1]>150, (s[:,1]>=100)&(s[:,1]<150), (s[:,1]>=50)&(s[:,1]<100), (s[:,1]>=20)&(s[:,1]<50), s[:,1]<20]).T\n",
    "s3 = np.array([s[:,2]<1.2, (s[:,2]>=1.2)&(s[:,2]<2), (s[:,2]>=2)&(s[:,2]<6), (s[:,2]>=6)&(s[:,2]<12), s[:,2]>12]).T\n",
    "s4 = np.array([s[:,3]>=70, (s[:,3]<70)&(s[:,3]>=65), s[:,3]<65, (s[:,4]>0)&(s[:,4]<=0.1), s[:,4]>0.1]).T\n",
    "s5 = np.array([s[:,5]>14, (s[:,5]>12)&(s[:,5]<=14), (s[:,5]>9)&(s[:,5]<=12), (s[:,5]>5)&(s[:,5]<=9), s[:,5]<=5]).T\n",
    "s6 = np.array([s[:,6]<1.2, (s[:,6]>=1.2)&(s[:,6]<2), (s[:,6]>=2)&(s[:,6]<3.5), ((s[:,6]>=3.5)&(s[:,6]<5))|(s[:,7]<84), (s[:,6]>5)|(s[:,7]<34)]).T\n",
    "\n",
    "scores = np.zeros((s.shape[0], 6))\n",
    "components = [s1, s2, s3, s4, s5, s6]\n",
    "\n",
    "for idx, comp in enumerate(components):\n",
    "    weighted = comp * p_points\n",
    "    scores[:, idx] = np.max(weighted, axis=1)\n",
    "\n",
    "reformat4t['SOFA'] = np.sum(scores, axis=1)\n",
    "\n",
    "# 9. HITUNG SIRS\n",
    "sirs_cols = {'Temp_C':37, 'HR':80, 'RR':15, 'paCO2':40, 'WBC_count':10} \n",
    "for col, val in sirs_cols.items():\n",
    "    if col not in reformat4t.columns:\n",
    "        reformat4t[col] = val\n",
    "    else:\n",
    "        reformat4t[col] = reformat4t[col].fillna(val)\n",
    "\n",
    "s_sirs = reformat4t[list(sirs_cols.keys())].values\n",
    "c1 = (s_sirs[:,0] > 38) | (s_sirs[:,0] < 36)\n",
    "c2 = s_sirs[:,1] > 90\n",
    "c3 = (s_sirs[:,2] >= 20) | (s_sirs[:,3] <= 32)\n",
    "c4 = (s_sirs[:,4] >= 12) | (s_sirs[:,4] < 4)\n",
    "\n",
    "reformat4t['SIRS'] = c1.astype(int) + c2.astype(int) + c3.astype(int) + c4.astype(int)\n",
    "\n",
    "print(\"Perhitungan SOFA & SIRS Selesai.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14. Eksklusi Pasien (Filter Akhir)\n",
    "\n",
    "**Tujuan:**\n",
    "Membuang pasien yang datanya tidak valid atau tidak memenuhi syarat metodologi.\n",
    "\n",
    "**Kriteria Pembuangan:**\n",
    "1.  **Extreme Outliers:**\n",
    "    * Urine Output > 12.000 ml (12 Liter) per 4 jam.\n",
    "    * Total Bilirubin > 10.000.\n",
    "    * Input Cairan > 10.000 ml per 4 jam.\n",
    "2.  **Withdrawal of Care:** Pasien yang meninggal karena penghentian perawatan (Vasopressor dihentikan padahal kondisi memburuk/SOFA tinggi).\n",
    "3.  **Data Incomplete:** Pasien yang meninggal dalam ICU tetapi pencatatan datanya terputus lebih dari 24 jam sebelum kematian.\n",
    "\n",
    "**Perbaikan Teknis:**\n",
    "* Memperbaiki logika `drop` yang salah indeks.\n",
    "* Menambahkan pengecekan ketersediaan kolom sebelum filtering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai Proses Eksklusi Pasien...\n",
      "Jumlah pasien awal: 20283\n",
      "  - Dibuang karena Urine ekstrem: 4 pasien\n",
      "  - Dibuang karena Bilirubin ekstrem: 0 pasien\n",
      "  - Dibuang karena Intake ekstrem: 31 pasien\n",
      "  - Dibuang karena Withdrawal/Early Death: 23 pasien\n",
      "  - Dibuang karena data terpotong (Missing Death Data): 1513 pasien\n",
      "SELESAI! Jumlah pasien akhir: 18712\n"
     ]
    }
   ],
   "source": [
    "print(\"Memulai Proses Eksklusi Pasien...\")\n",
    "\n",
    "initial_count = np.unique(reformat4t['icustayid']).size\n",
    "print(f\"Jumlah pasien awal: {initial_count}\")\n",
    "\n",
    "# 1. Outlier Urine (> 12L / 4 jam)\n",
    "if 'output_4hourly' in reformat4t.columns:\n",
    "    outlier_mask = reformat4t['output_4hourly'].values > 12000\n",
    "    ids_remove = np.unique(reformat4t.loc[outlier_mask, 'icustayid'])\n",
    "    reformat4t = reformat4t[~reformat4t['icustayid'].isin(ids_remove)].copy()\n",
    "    print(f\"  - Dibuang karena Urine ekstrem: {len(ids_remove)} pasien\")\n",
    "\n",
    "# 2. Outlier Bilirubin (> 10000)\n",
    "if 'Total_bili' in reformat4t.columns:\n",
    "    outlier_mask = reformat4t['Total_bili'].values > 10000\n",
    "    ids_remove = np.unique(reformat4t.loc[outlier_mask, 'icustayid'])\n",
    "    reformat4t = reformat4t[~reformat4t['icustayid'].isin(ids_remove)].copy()\n",
    "    print(f\"  - Dibuang karena Bilirubin ekstrem: {len(ids_remove)} pasien\")\n",
    "\n",
    "# 3. Outlier Intake (> 10L / 4 jam)\n",
    "if 'input_4hourly' in reformat4t.columns:\n",
    "    outlier_mask = reformat4t['input_4hourly'].values > 10000\n",
    "    ids_remove = np.unique(reformat4t.loc[outlier_mask, 'icustayid'])\n",
    "    reformat4t = reformat4t[~reformat4t['icustayid'].isin(ids_remove)].copy()\n",
    "    print(f\"  - Dibuang karena Intake ekstrem: {len(ids_remove)} pasien\")\n",
    "\n",
    "# 4. Exclude Early Deaths / Withdrawals (Palliative Care)\n",
    "# Hitung statistik per pasien\n",
    "grp = reformat4t.groupby('icustayid')\n",
    "d = grp.agg({\n",
    "    'mortality_90d': 'max',\n",
    "    'max_dose_vaso': 'max',\n",
    "    'SOFA': 'max',\n",
    "    'bloc': 'count' \n",
    "}).reset_index()\n",
    "d.rename(columns={'bloc': 'GroupCount'}, inplace=True)\n",
    "\n",
    "# Gabungkan info statistik ke data baris terakhir setiap pasien\n",
    "last_rows = reformat4t.drop_duplicates('icustayid', keep='last').copy()\n",
    "last_rows = last_rows.merge(d[['icustayid', 'max_dose_vaso', 'SOFA', 'GroupCount']], \n",
    "                           on='icustayid', suffixes=('', '_max'))\n",
    "\n",
    "# Logic Withdrawal:\n",
    "# Meninggal (Morta=1) DAN\n",
    "# Stop Vaso (Vaso Akhir=0) tapi Vaso Pernah Tinggi (Max > 0.3) DAN\n",
    "# Kondisi Masih Buruk (SOFA Akhir >= Setengah Max SOFA)\n",
    "cond1 = last_rows['mortality_90d'] == 1\n",
    "cond2 = last_rows['max_dose_vaso'] == 0\n",
    "cond3 = last_rows['max_dose_vaso_max'] > 0.3\n",
    "cond4 = last_rows['SOFA'] >= (last_rows['SOFA_max'] / 2)\n",
    "cond5 = last_rows['GroupCount'] < 20 # Data < 80 jam\n",
    "\n",
    "ids_withdrawal = last_rows.loc[cond1 & cond2 & cond3 & cond4 & cond5, 'icustayid'].values\n",
    "reformat4t = reformat4t[~reformat4t['icustayid'].isin(ids_withdrawal)].copy()\n",
    "print(f\"  - Dibuang karena Withdrawal/Early Death: {len(ids_withdrawal)} pasien\")\n",
    "\n",
    "# 5. Exclude Missing Death Data\n",
    "# Meninggal di ICU tapi data stop > 24 jam sebelumnya\n",
    "if 'died_within_48h_of_out_time' in reformat4t.columns:\n",
    "    # Ambil baris pertama saja per pasien untuk cek atribut statis ini\n",
    "    first_rows = reformat4t.drop_duplicates('icustayid', keep='first')\n",
    "    \n",
    "    cond_died = first_rows['died_within_48h_of_out_time'] == 1\n",
    "    cond_delay = first_rows['delay_end_of_record_and_discharge_or_death'] < 24\n",
    "    \n",
    "    ids_bad_data = first_rows.loc[cond_died & cond_delay, 'icustayid'].values\n",
    "    \n",
    "    # PERBAIKAN UTAMA: Gunakan .isin() untuk drop, bukan index dari list lain\n",
    "    reformat4t = reformat4t[~reformat4t['icustayid'].isin(ids_bad_data)].copy()\n",
    "    print(f\"  - Dibuang karena data terpotong (Missing Death Data): {len(ids_bad_data)} pasien\")\n",
    "\n",
    "reformat4t.reset_index(inplace=True, drop=True)\n",
    "final_count = np.unique(reformat4t['icustayid']).size\n",
    "print(f\"SELESAI! Jumlah pasien akhir: {final_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 15. Finalisasi Kohort Sepsis & Penyimpanan Data\n",
    "\n",
    "**Tujuan:**\n",
    "Membuat daftar final pasien Sepsis (Cohorts) berdasarkan kriteria Sepsis-3 dan menyimpan dataset bersih.\n",
    "\n",
    "**Kriteria Final:**\n",
    "* Pasien harus memiliki `onset` infeksi (Kultur + Antibiotik).\n",
    "* Skor SOFA maksimal $\\ge$ 2 poin (menandakan disfungsi organ akut).\n",
    "\n",
    "**Output:**\n",
    "* `sepsis_mimiciii.csv`: Daftar ID pasien yang lolos seleksi.\n",
    "* `step_3_start.pkl`: Backup semua variabel data mentah untuk digunakan di Notebook selanjutnya (Feature Engineering)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Membuat Final Sepsis Cohort...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|███▊                              | 11386/100000 [00:01<00:09, 9195.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|███████▎                          | 21618/100000 [00:02<00:08, 9492.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 20000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|██████████▌                       | 31053/100000 [00:03<00:07, 9461.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 30000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|██████████████▏                   | 41735/100000 [00:04<00:06, 9596.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 40000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████████████████▎                | 51074/100000 [00:05<00:05, 9150.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 50000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|████████████████████▊             | 61249/100000 [00:06<00:04, 9186.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 60000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|████████████████████████▏         | 71303/100000 [00:07<00:03, 8953.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 70000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|███████████████████████████▋      | 81521/100000 [00:08<00:01, 9306.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 80000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|███████████████████████████████▏  | 91738/100000 [00:10<00:00, 9150.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 90000...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 100000/100000 [00:10<00:00, 9137.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 100000...\n",
      "Total kandidat awal: 18712\n",
      "Jumlah Pasien Sepsis Final: 16583\n",
      "File 'sepsis_mimiciii.csv' berhasil disimpan.\n",
      "Menyimpan Backup Pickle (Ini mungkin lama)...\n",
      "Backup 'step_3_start.pkl' BERHASIL disimpan!\n",
      "PROSES NOTEBOOK 2 SELESAI!\n"
     ]
    }
   ],
   "source": [
    "print(\"Membuat Final Sepsis Cohort...\")\n",
    "\n",
    "# Inisialisasi\n",
    "# Kita siapkan array 30.000 baris (Estimasi jumlah pasien sepsis)\n",
    "sepsis = np.zeros((30000, 5)) \n",
    "irow = 0\n",
    "\n",
    "# Loop 1 s.d 100.000\n",
    "for icustayid_idx in tqdm(range(1, 100001)):\n",
    "    \n",
    "    # PERBAIKAN LOGIC: Konversi ke Real ID (200xxx) untuk pencocokan\n",
    "    real_icustayid = icustayid_idx + 200000\n",
    "    \n",
    "    # Cari data pasien ini di reformat4t\n",
    "    # Gunakan boolean indexing (lebih cepat dari np.isin single value)\n",
    "    ii = np.where(reformat4t['icustayid'] == real_icustayid)[0]\n",
    "    \n",
    "    if icustayid_idx % 10000 == 0: \n",
    "        print(f\"Processing {icustayid_idx}...\")\n",
    "        \n",
    "    if ii.size > 0:     \n",
    "        # Ambil data skor\n",
    "        sofa = reformat4t.iloc[ii]['SOFA'] \n",
    "        sirs = reformat4t.iloc[ii]['SIRS'] \n",
    "        \n",
    "        # Isi Array Sepsis\n",
    "        sepsis[irow, 0] = real_icustayid\n",
    "        sepsis[irow, 1] = reformat4t.iloc[ii[0]]['mortality_90d'] # 90-day mortality\n",
    "        sepsis[irow, 2] = sofa.max()\n",
    "        sepsis[irow, 3] = sirs.max()\n",
    "        sepsis[irow, 4] = qstime[icustayid_idx-1, 0]   # Time of onset\n",
    "        \n",
    "        irow += 1\n",
    "\n",
    "# Potong array kosong\n",
    "sepsis = sepsis[:irow, :]\n",
    "\n",
    "# Convert ke DataFrame\n",
    "sepsis_df = pd.DataFrame(sepsis, columns=['icustayid','morta_90d','max_sofa','max_sirs','sepsis_time']) \n",
    "\n",
    "# Filter Non-Sepsis (Hapus yang Max SOFA < 2)\n",
    "print(f\"Total kandidat awal: {len(sepsis_df)}\")\n",
    "sepsis_df = sepsis_df[sepsis_df['max_sofa'] >= 2].copy()\n",
    "sepsis_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Final count\n",
    "print(f\"Jumlah Pasien Sepsis Final: {len(sepsis_df)}\")\n",
    "\n",
    "# Save CSV\n",
    "sepsis_df.to_csv('sepsis_mimiciii.csv', index=False, na_rep='NaN')   \n",
    "print(\"File 'sepsis_mimiciii.csv' berhasil disimpan.\")\n",
    "\n",
    "# Save to pickle for step 3 (Backup Besar)\n",
    "print(\"Menyimpan Backup Pickle (Ini mungkin lama)...\")\n",
    "try:\n",
    "    with open('step_3_start.pkl', 'wb') as file:\n",
    "        pickle.dump(sample_and_hold, file)\n",
    "        pickle.dump(demog, file)\n",
    "        # Dump Vitals Chunks\n",
    "        pickle.dump(ce010, file); pickle.dump(ce1020, file); pickle.dump(ce2030, file)\n",
    "        pickle.dump(ce3040, file); pickle.dump(ce4050, file); pickle.dump(ce5060, file)\n",
    "        pickle.dump(ce6070, file); pickle.dump(ce7080, file); pickle.dump(ce8090, file); pickle.dump(ce90100, file)\n",
    "        # Dump Other Data\n",
    "        pickle.dump(labU, file)\n",
    "        pickle.dump(MV, file)\n",
    "        pickle.dump(inputpreadm, file); pickle.dump(inputMV, file); pickle.dump(inputCV, file)\n",
    "        pickle.dump(vasoMV, file); pickle.dump(vasoCV, file)\n",
    "        pickle.dump(UOpreadm, file); pickle.dump(UO, file) \n",
    "        # Dump Result\n",
    "        pickle.dump(sepsis_df, file)\n",
    "        \n",
    "    print(\"Backup 'step_3_start.pkl' BERHASIL disimpan!\")\n",
    "except Exception as e:\n",
    "    print(\"⚠️ Gagal menyimpan Pickle (Kemungkinan RAM/Disk penuh):\", e)\n",
    "    print(\"Tapi jangan khawatir, file CSV utama 'sepsis_mimiciii.csv' sudah aman.\")\n",
    "\n",
    "print(\"PROSES NOTEBOOK 2 SELESAI!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
